{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ea47f2",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mikonvergence/DiffusionFastForward/blob/master/01-colab-Diffusion-Sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b82ff",
   "metadata": {},
   "source": [
    "> This is part of [DiffusionFastForward](https://github.com/mikonvergence/DiffusionFastForward) course. For more content, please go to https://github.com/mikonvergence/DiffusionFastForward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce528bb2",
   "metadata": {},
   "source": [
    "# Diffusion Sandbox - æ‰©æ•£æ¨¡å‹å®éªŒå®¤\n",
    "\n",
    "[English]\n",
    "In this notebook, the intricacies of a denosing diffusion framework are illustrated with the aid of simple snippets.\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "åœ¨è¿™ä¸ªnotebookä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ç®€å•çš„ä»£ç ç¤ºä¾‹æ¥è¯¦ç»†è¯´æ˜å»å™ªæ‰©æ•£æ¨¡å‹(Denoising Diffusion)çš„å·¥ä½œåŸç†ã€‚æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç±»å¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒé€šè¿‡é€æ­¥å‘æ•°æ®æ·»åŠ å™ªå£°ï¼Œç„¶åå­¦ä¹ åå‘å»å™ªè¿‡ç¨‹æ¥ç”Ÿæˆæ–°çš„æ•°æ®ã€‚\n",
    "\n",
    "First, let's import an image to use for the examples.\n",
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥ä¸€å¼ å›¾ç‰‡ä½œä¸ºç¤ºä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9tRm5DS3n0Kt",
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/mikonvergence/DiffusionFastForward\n",
    "!pip install pytorch-lightning==1.9.3 diffusers einops kornia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CfUrnwAsofFc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./DiffusionFastForward/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "img = torch.FloatTensor(imageio.imread('./DiffusionFastForward/imgs/hills_2.png')/255)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b7cd",
   "metadata": {},
   "source": [
    "### Before we start... å¼€å§‹ä¹‹å‰...\n",
    "\n",
    "[English]\n",
    "The majority of the diffusion models assume that the images are scaled to the `[-1,+1]` range (which tends to simplify many equations). This tutorial will follow the same approach, so we need to define input and output transformation functions `input_T()` and `output_T()`.\n",
    "\n",
    "Also, let's define our own `show()` wrapper function that displays the image with automatic output transformation!\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "å¤§å¤šæ•°æ‰©æ•£æ¨¡å‹å‡è®¾å›¾åƒè¢«ç¼©æ”¾åˆ° `[-1,+1]` çš„èŒƒå›´å†…ï¼ˆè¿™æ ·å¯ä»¥ç®€åŒ–è®¸å¤šå…¬å¼ï¼‰ã€‚æœ¬æ•™ç¨‹ä¹Ÿå°†é‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å®šä¹‰è¾“å…¥å’Œè¾“å‡ºè½¬æ¢å‡½æ•° `input_T()` å’Œ `output_T()`ã€‚\n",
    "\n",
    "åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜å°†å®šä¹‰ä¸€ä¸ªè‡ªå·±çš„ `show()` åŒ…è£…å‡½æ•°ï¼Œå®ƒå¯ä»¥åœ¨æ˜¾ç¤ºå›¾åƒæ—¶è‡ªåŠ¨è¿›è¡Œè¾“å‡ºè½¬æ¢ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_T(input):\n",
    "    # [0,1] -> [-1,+1]\n",
    "    return 2*input-1\n",
    "    \n",
    "def output_T(input):\n",
    "    # [-1,+1] -> [0,1]\n",
    "    return (input+1)/2\n",
    "\n",
    "def show(input):\n",
    "    plt.imshow(output_T(input).clip(0,1))\n",
    "    \n",
    "img_=input_T(img)\n",
    "show(img_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823147d9",
   "metadata": {},
   "source": [
    "### Defining a schedule å®šä¹‰å™ªå£°è°ƒåº¦\n",
    "\n",
    "[English]\n",
    "The diffusion process is built based on a variance schedule, which determines the levels of added noise at each step of the process. To that end, our schedule is defined below, with the following quantities:\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "æ‰©æ•£è¿‡ç¨‹æ˜¯åŸºäºä¸€ä¸ªæ–¹å·®è°ƒåº¦(variance schedule)æ„å»ºçš„ï¼Œå®ƒå†³å®šäº†åœ¨è¿‡ç¨‹çš„æ¯ä¸€æ­¥ä¸­æ·»åŠ å™ªå£°çš„ç¨‹åº¦ã€‚æˆ‘ä»¬çš„è°ƒåº¦åŒ…å«ä»¥ä¸‹é‡è¦å‚æ•°ï¼š\n",
    "\n",
    "* `betas`:$\\beta_t$ \n",
    "  - [EN] The variance schedule that controls noise addition at each step\n",
    "  - [CN] æ§åˆ¶æ¯ä¸€æ­¥æ·»åŠ å™ªå£°é‡çš„æ–¹å·®è°ƒåº¦\n",
    "\n",
    "* `alphas`: $\\alpha_t=1-\\beta_t$\n",
    "  - [EN] Complement of betas, represents signal preservation at each step\n",
    "  - [CN] betasçš„è¡¥æ•°ï¼Œè¡¨ç¤ºæ¯ä¸€æ­¥ä¸­ä¿¡å·ä¿ç•™çš„ç¨‹åº¦\n",
    "\n",
    "* `alphas_sqrt`:  $\\sqrt{\\alpha_t}$ \n",
    "  - [EN] Square root of alphas, used in noise scaling\n",
    "  - [CN] alphasçš„å¹³æ–¹æ ¹ï¼Œç”¨äºå™ªå£°ç¼©æ”¾\n",
    "\n",
    "* `alphas_prod`: $\\bar{\\alpha}_t=\\prod_{i=0}^{t}\\alpha_i$ \n",
    "  - [EN] Cumulative product of alphas up to step t\n",
    "  - [CN] ä»å¼€å§‹åˆ°æ­¥éª¤tçš„alphasç´¯ç§¯ä¹˜ç§¯\n",
    "\n",
    "* `alphas_prod_sqrt`: $\\sqrt{\\bar{\\alpha}_t}$ \n",
    "  - [EN] Square root of cumulative alphas product\n",
    "  - [CN] ç´¯ç§¯alphasä¹˜ç§¯çš„å¹³æ–¹æ ¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494b544",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps=1000\n",
    "betas=torch.linspace(1e-4,2e-2,num_timesteps)\n",
    "\n",
    "alphas=1-betas\n",
    "alphas_sqrt=alphas.sqrt()\n",
    "alphas_cumprod=torch.cumprod(alphas,0)\n",
    "alphas_cumprod_sqrt=alphas_cumprod.sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576f376",
   "metadata": {},
   "source": [
    "## Forward Process å‰å‘è¿‡ç¨‹\n",
    "\n",
    "[English]\n",
    "The forward process $q$ determines how subsequent steps in the diffusion are derived (gradual distortion of the original sample $x_0$).\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "å‰å‘è¿‡ç¨‹ $q$ å†³å®šäº†æ‰©æ•£è¿‡ç¨‹ä¸­åç»­æ­¥éª¤æ˜¯å¦‚ä½•æ¨å¯¼çš„ï¼ˆåŸå§‹æ ·æœ¬ $x_0$ çš„é€æ­¥æ‰°åŠ¨ï¼‰ã€‚\n",
    "\n",
    "ğŸ“ƒ First, let's bring up the key equations describing this process...\n",
    "è®©æˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æè¿°è¿™ä¸ªè¿‡ç¨‹çš„å…³é”®æ–¹ç¨‹...\n",
    "\n",
    "[English]\n",
    "Basic format of the forward step:\n",
    "[ä¸­æ–‡]\n",
    "å‰å‘æ­¥éª¤çš„åŸºæœ¬æ ¼å¼ï¼š\n",
    "\n",
    "$$q(x_t|x_{tâˆ’1}) := \\mathcal{N}(x_t; \\sqrt{1 âˆ’ \\beta_t}x_{tâˆ’1}, \\beta_tI) \\tag{1}$$\n",
    "\n",
    "[English]\n",
    "to step directly from $x_0$ to $x_t$:\n",
    "[ä¸­æ–‡]\n",
    "ç›´æ¥ä» $x_0$ åˆ° $x_t$ çš„æ­¥éª¤ï¼š\n",
    "\n",
    "$$q(x_t|x_0) = \\mathcal{N}(x_t;\\sqrt{\\bar{\\alpha_t}}x_0, (1 âˆ’ \\bar{\\alpha_t})I) \\tag{2}$$\n",
    "\n",
    "[ä¸­æ–‡è§£é‡Š]\n",
    "è¿™ä¸¤ä¸ªæ–¹ç¨‹æè¿°äº†æ‰©æ•£è¿‡ç¨‹ä¸­çš„å™ªå£°æ·»åŠ æœºåˆ¶ï¼š\n",
    "1. æ–¹ç¨‹(1)æè¿°äº†å¦‚ä½•ä»æ—¶é—´æ­¥ t-1 åˆ° t æ·»åŠ å™ªå£°\n",
    "2. æ–¹ç¨‹(2)æè¿°äº†å¦‚ä½•ç›´æ¥ä»åŸå§‹å›¾åƒè·³è½¬åˆ°ä»»æ„æ—¶é—´æ­¥ t\n",
    "3. $\\mathcal{N}$ è¡¨ç¤ºæ­£æ€åˆ†å¸ƒï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯å‡å€¼ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯æ–¹å·®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef306b72",
   "metadata": {},
   "source": [
    "### Let's define a function `forward_step()` that will allow us to use both $q(x_t|x_{t-1})$ and  `forward_jump()` for $q(x_t|x_0)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1976dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_step(t, condition_img, return_noise=False):\n",
    "    \"\"\"\n",
    "    [EN] Forward step: t-1 -> t\n",
    "         Performs a single step in the forward diffusion process\n",
    "    \n",
    "    [CN] å‰å‘æ­¥éª¤ï¼šä»t-1åˆ°t\n",
    "         æ‰§è¡Œå‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­çš„å•ä¸ªæ­¥éª¤\n",
    "    \"\"\"    \n",
    "    assert t >= 0\n",
    "\n",
    "    # [CN] è®¡ç®—å‡å€¼ï¼šä½¿ç”¨alphaçš„å¹³æ–¹æ ¹ç¼©æ”¾æ¡ä»¶å›¾åƒ\n",
    "    mean=alphas_sqrt[t]*condition_img    \n",
    "    # [CN] è®¡ç®—æ ‡å‡†å·®ï¼šä½¿ç”¨betaçš„å¹³æ–¹æ ¹\n",
    "    std=betas[t].sqrt()\n",
    "      \n",
    "    # [CN] ä»æ­£æ€åˆ†å¸ƒNä¸­é‡‡æ ·\n",
    "    if not return_noise:\n",
    "        return mean+std*torch.randn_like(img)\n",
    "    else:\n",
    "        noise=torch.randn_like(img)\n",
    "        return mean+std*noise, noise\n",
    "    \n",
    "def forward_jump(t, condition_img, condition_idx=0, return_noise=False):\n",
    "    \"\"\"\n",
    "    [EN] Forward jump: 0 -> t\n",
    "         Directly jumps from x_0 to x_t in the forward diffusion process\n",
    "    \n",
    "    [CN] å‰å‘è·³è·ƒï¼šä»0ç›´æ¥åˆ°t\n",
    "         åœ¨å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ä»x_0ç›´æ¥è·³è·ƒåˆ°x_t\n",
    "    \"\"\"   \n",
    "    assert t >= 0\n",
    "    \n",
    "    # [CN] è®¡ç®—å‡å€¼ï¼šä½¿ç”¨ç´¯ç§¯alphaçš„å¹³æ–¹æ ¹ç¼©æ”¾æ¡ä»¶å›¾åƒ\n",
    "    mean=alphas_cumprod_sqrt[t]*condition_img\n",
    "    # [CN] è®¡ç®—æ ‡å‡†å·®ï¼šä½¿ç”¨ç´¯ç§¯alphaçš„è¡¥æ•°çš„å¹³æ–¹æ ¹\n",
    "    std=(1-alphas_cumprod[t]).sqrt()\n",
    "      \n",
    "    # [CN] ä»æ­£æ€åˆ†å¸ƒNä¸­é‡‡æ ·\n",
    "    if not return_noise:\n",
    "        return mean+std*torch.randn_like(img)\n",
    "    else:\n",
    "        noise=torch.randn_like(img)\n",
    "        return mean+std*noise, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=5 # number of computed states between x_0 and x_T\n",
    "M=4 # number of samples taken from each distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea926a",
   "metadata": {},
   "source": [
    "[English]\n",
    "In the first example, when `t==0`, we want to derive a sample $x_t$ based on the clean sample $x_0$!\n",
    "\n",
    "The first column shows the mean image for a given stage of the diffusion, and the subsequent columns to the right show several samples taken from the same distribution (they are different if you look closely!)\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "åœ¨ç¬¬ä¸€ä¸ªç¤ºä¾‹ä¸­ï¼Œå½“ `t==0` æ—¶ï¼Œæˆ‘ä»¬è¦åŸºäºå¹²å‡€çš„æ ·æœ¬ $x_0$ æ¨å¯¼å‡ºæ ·æœ¬ $x_t$ï¼\n",
    "\n",
    "ç¬¬ä¸€åˆ—æ˜¾ç¤ºäº†æ‰©æ•£è¿‡ç¨‹ä¸­ç»™å®šé˜¶æ®µçš„å‡å€¼å›¾åƒï¼Œå³ä¾§çš„åç»­åˆ—æ˜¾ç¤ºäº†ä»åŒä¸€åˆ†å¸ƒä¸­é‡‡æ ·çš„å‡ ä¸ªæ ·æœ¬ï¼ˆä»”ç»†è§‚å¯Ÿçš„è¯ï¼Œå®ƒä»¬æ˜¯ä¸åŒçš„ï¼ï¼‰\n",
    "\n",
    "[å¯è§†åŒ–è¯´æ˜]\n",
    "- æ¯ä¸€è¡Œä»£è¡¨æ‰©æ•£è¿‡ç¨‹ä¸­çš„ä¸åŒæ—¶é—´æ­¥\n",
    "- æœ€å·¦è¾¹çš„å›¾åƒæ˜¯è¯¥æ—¶é—´æ­¥çš„å‡å€¼ï¼ˆç¡®å®šæ€§çš„ï¼‰\n",
    "- å³è¾¹çš„å›¾åƒæ˜¯åŠ å…¥éšæœºå™ªå£°åçš„ç»“æœï¼ˆéšæœºçš„ï¼‰\n",
    "- ä»ä¸Šåˆ°ä¸‹å¯ä»¥çœ‹åˆ°å›¾åƒé€æ¸è¢«å™ªå£°ç ´åçš„è¿‡ç¨‹."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3dc1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for idx in range(N):\n",
    "    t_step=int(idx*(num_timesteps/N))\n",
    "    \n",
    "    plt.subplot(N,1+M,1+(M+1)*idx)\n",
    "    show(alphas_cumprod_sqrt[t_step]*img_)\n",
    "    plt.title(r'$\\mu_t=\\sqrt{\\bar{\\alpha}_t}x_0$') if idx==0 else None\n",
    "    plt.ylabel(\"t: {:.2f}\".format(t_step/num_timesteps))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    for sample in range(M):\n",
    "        x_t=forward_jump(t_step,img_)\n",
    "        \n",
    "        plt.subplot(N,1+M,2+(1+M)*idx+sample)\n",
    "        show(x_t)        \n",
    "        plt.axis('off')\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639a95d",
   "metadata": {},
   "source": [
    "Alternatively, we can test the process of going from $x_{t-1}$ to $x_t$, which is a single step in the diffusion process. For that we can use the `forward_step` function.\n",
    "\n",
    "Note that the mean $\\mu_t$ is now a bit different (first column) since it is conditioned on a specific sample of $x_{t-1}$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for idx in range(N):\n",
    "    t_step=int(idx*(num_timesteps/N))\n",
    "    prev_img=forward_jump(max([0,t_step-1]),img_) # directly go to prev state\n",
    "    \n",
    "    plt.subplot(N,1+M,1+(M+1)*idx)\n",
    "    show(alphas_sqrt[t_step]*prev_img)\n",
    "    plt.title(r'$\\mu_t=\\sqrt{1-\\beta_t}x_{t-1}$') if idx==0 else None\n",
    "    plt.ylabel(\"t: {:.2f}\".format(t_step/num_timesteps))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    for sample in range(M):\n",
    "        plt.subplot(N,1+M,2+(1+M)*idx+sample)\n",
    "        x_t=forward_step(t_step,prev_img)\n",
    "        show(x_t)        \n",
    "        plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa53f91c",
   "metadata": {},
   "source": [
    "## Reverse Process åå‘è¿‡ç¨‹\n",
    "\n",
    "[English]\n",
    "The purpose of the reverse process $p$ is to approximate the previous step $x_{t-1}$ in the diffusion chain based on a sample $x_t$. In practice, this approximation $p(x_{t-1}|x_t)$ must be done without the knowledge of $x_0$.\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "åå‘è¿‡ç¨‹ $p$ çš„ç›®çš„æ˜¯åŸºäºæ ·æœ¬ $x_t$ æ¥è¿‘ä¼¼æ‰©æ•£é“¾ä¸­çš„å‰ä¸€æ­¥ $x_{t-1}$ã€‚åœ¨å®è·µä¸­ï¼Œè¿™ä¸ªè¿‘ä¼¼ $p(x_{t-1}|x_t)$ å¿…é¡»åœ¨ä¸çŸ¥é“ $x_0$ çš„æƒ…å†µä¸‹å®Œæˆã€‚\n",
    "\n",
    "[English]\n",
    "A parametrizable prediction model with parameters $\\theta$ is used to estimate $p_\\theta(x_{t-1}|x_t)$.\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå¸¦å‚æ•° $\\theta$ çš„å¯å‚æ•°åŒ–é¢„æµ‹æ¨¡å‹æ¥ä¼°è®¡ $p_\\theta(x_{t-1}|x_t)$ã€‚\n",
    "\n",
    "[English]\n",
    "The reverse process will also be (approximately) gaussian if the diffusion steps are small enough:\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "å¦‚æœæ‰©æ•£æ­¥éª¤è¶³å¤Ÿå°ï¼Œåå‘è¿‡ç¨‹ä¹Ÿå°†ï¼ˆè¿‘ä¼¼ï¼‰æœä»é«˜æ–¯åˆ†å¸ƒï¼š\n",
    "\n",
    "$$p_\\theta(x_{t-1}|x_t) := \\mathcal{N}(x_{t-1};\\mu_\\theta(x_t),\\Sigma_\\theta(x_t))\\tag{3}$$\n",
    "\n",
    "[English]\n",
    "In many works, it is assumed that the variance of this distribution should not depend strongly on $x_0$ or $x_t$, but rather on the stage of the diffusion process $t$. This can be observed in the true distribution $q(x_{t-1}|x_t, x_0)$, where the variance of the distribution equals $\\tilde{\\beta}_t$.\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "åœ¨è®¸å¤šç ”ç©¶ä¸­ï¼Œéƒ½å‡è®¾è¿™ä¸ªåˆ†å¸ƒçš„æ–¹å·®ä¸åº”è¯¥å¼ºçƒˆä¾èµ–äº $x_0$ æˆ– $x_t$ï¼Œè€Œæ˜¯ä¸»è¦ä¾èµ–äºæ‰©æ•£è¿‡ç¨‹çš„é˜¶æ®µ $t$ã€‚è¿™ä¸€ç‚¹å¯ä»¥åœ¨çœŸå®åˆ†å¸ƒ $q(x_{t-1}|x_t, x_0)$ ä¸­è§‚å¯Ÿåˆ°ï¼Œå…¶ä¸­åˆ†å¸ƒçš„æ–¹å·®ç­‰äº $\\tilde{\\beta}_t$ã€‚\n",
    "\n",
    "[è¡¥å……è¯´æ˜]\n",
    "åå‘è¿‡ç¨‹æ˜¯æ‰©æ•£æ¨¡å‹ä¸­æœ€å…³é”®çš„éƒ¨åˆ†ï¼Œå› ä¸ºå®ƒå®é™…ä¸Šå°±æ˜¯æˆ‘ä»¬çš„ç”Ÿæˆæ¨¡å‹ã€‚é€šè¿‡å­¦ä¹ å¦‚ä½•é€æ­¥å»é™¤å™ªå£°ï¼Œæ¨¡å‹æœ€ç»ˆèƒ½å¤Ÿä»çº¯å™ªå£°ç”Ÿæˆæœ‰æ„ä¹‰çš„æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03ecb3d",
   "metadata": {},
   "source": [
    "### Parameterizing $\\mu_\\theta$ å‚æ•°åŒ–å‡å€¼ $\\mu_\\theta$\n",
    "\n",
    "[English]\n",
    "There are at least 3 ways of parameterizing the mean of the reverse step distribution $p_\\theta(x_{t-1}|x_t)$:\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "åå‘æ­¥éª¤åˆ†å¸ƒ $p_\\theta(x_{t-1}|x_t)$ çš„å‡å€¼è‡³å°‘æœ‰3ç§å‚æ•°åŒ–æ–¹å¼ï¼š\n",
    "\n",
    "1. [EN] Directly (a neural network will estimate $\\mu_\\theta$)\n",
    "   [CN] ç›´æ¥æ–¹å¼ï¼ˆç¥ç»ç½‘ç»œç›´æ¥ä¼°è®¡ $\\mu_\\theta$ï¼‰\n",
    "\n",
    "2. [EN] Via $x_0$ (a neural network will estimate $x_0$)\n",
    "   [CN] é€šè¿‡ $x_0$ æ–¹å¼ï¼ˆç¥ç»ç½‘ç»œä¼°è®¡ $x_0$ï¼‰\n",
    "$$\\tilde{\\mu}_\\theta = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1-\\bar{\\alpha}_t}x_0 + \\frac{\\sqrt{\\alpha_t}(1-\\bar{\\alpha}_{t-1})}{1-\\bar{\\alpha}_t}x_t\\tag{4}$$\n",
    "\n",
    "3. [EN] Via noise $\\epsilon$ subtraction from $x_0$ (a neural network will estimate $\\epsilon$)\n",
    "   [CN] é€šè¿‡ä» $x_0$ ä¸­å‡å»å™ªå£° $\\epsilon$ çš„æ–¹å¼ï¼ˆç¥ç»ç½‘ç»œä¼°è®¡ $\\epsilon$ï¼‰\n",
    "$$x_0=\\frac{1}{\\sqrt{\\bar{\\alpha}_t}}(x_t-\\sqrt{1-\\bar{\\alpha}_t}\\epsilon)\\tag{5}$$\n",
    "\n",
    "[English]\n",
    "The approach of approximating the normal noise $\\epsilon$ is used most widely.\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "ä¼°è®¡æ­£æ€å™ªå£° $\\epsilon$ çš„æ–¹æ³•æ˜¯æœ€å¹¿æ³›ä½¿ç”¨çš„ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜åŠ¿åœ¨äºå®ƒå¯ä»¥è®©æ¨¡å‹ç›´æ¥å­¦ä¹ å™ªå£°çš„åˆ†å¸ƒï¼Œè¿™é€šå¸¸æ¯”å­¦ä¹ åŸå§‹æ•°æ®æˆ–ä¸­é—´çŠ¶æ€æ›´å®¹æ˜“ã€‚\n",
    "\n",
    "[English]\n",
    "Let's look at what an example $\\epsilon$ might look like:\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹ä¸€ä¸ª $\\epsilon$ å™ªå£°çš„ç¤ºä¾‹æ˜¯ä»€ä¹ˆæ ·å­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596c106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_step=50\n",
    "\n",
    "x_t,noise=forward_jump(t_step,img_,return_noise=True)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "show(img_)\n",
    "plt.title(r'$x_0$')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "show(x_t)\n",
    "plt.title(r'$x_t$')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "show(noise)\n",
    "plt.title(r'$\\epsilon$')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c01ffb",
   "metadata": {},
   "source": [
    "If $\\epsilon$ is predicted correctly, we can use the equation (5) to predict $x_0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0_pred=(x_t-(1-alphas_cumprod[t_step]).sqrt()*noise)/(alphas_cumprod_sqrt[t_step])\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "show(x_t)\n",
    "plt.title('$x_t$ ($\\ell_1$: {:.3f})'.format(F.l1_loss(x_t,img_)))\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "show(x_0_pred)\n",
    "plt.title('$x_0$ prediction ($\\ell_1$: {:.3f})'.format(F.l1_loss(x_0_pred,img_)))\n",
    "plt.axis('off') \n",
    "plt.subplot(1,3,3)\n",
    "show(img_)\n",
    "plt.title('$x_0$')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8841689c",
   "metadata": {},
   "source": [
    "Approximation (or knowledge) of $x_0$ allows us to approximate the mean of the step $t-1$, using (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate mean\n",
    "mean_pred=x_0_pred*(alphas_cumprod_sqrt[t_step-1]*betas[t_step])/(1-alphas_cumprod[t_step]) + x_t*(alphas_sqrt[t_step]*(1-alphas_cumprod[t_step-1]))/(1-alphas_cumprod[t_step])\n",
    "\n",
    "# let's compare it to ground truth mean of the previous step (requires knowledge of x_0)\n",
    "mean_gt=alphas_cumprod_sqrt[t_step-1]*img_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffd11d7",
   "metadata": {},
   "source": [
    "Since reverse process mean estimation $\\tilde{\\mu}_\\theta$ in (4) is effectively linear interpolation between noisy $x_t$ and $x_0$ it is expected to have a higher error (as the additive noise is still present) compared to the mean computed using the forward process (which is computed by scaling the clean sample by a scalar value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,3,1)\n",
    "show(x_t)\n",
    "plt.title('$x_t$   ($\\ell_1$: {:.3f})'.format(F.l1_loss(x_t,img_)))\n",
    "plt.subplot(1,3,2)\n",
    "show(mean_pred)\n",
    "plt.title(r'$\\tilde{\\mu}_{t-1}$' + '  ($\\ell_1$: {:.3f})'.format(F.l1_loss(mean_pred,img_)))\n",
    "plt.subplot(1,3,3)\n",
    "show(mean_gt)\n",
    "plt.title(r'$\\mu_{t-1}$' + '  ($\\ell_1$: {:.3f})'.format(F.l1_loss(mean_gt,img_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30f0d7",
   "metadata": {},
   "source": [
    "Once we get our `mean_pred` ($\\tilde{\\mu_{t}}$), we can define our distribution for the previous step\n",
    "\n",
    "$$\\tilde{\\beta}_t=\\beta_t \\tag{6}$$\n",
    "\n",
    "$$ p_\\theta(x_{t-1}|x_t) := \\mathcal{N}(x_{t-1};\\tilde{\\mu}_\\theta(x_t,t),\\tilde{\\beta}_t I) \\tag{7}$$\n",
    "\n",
    "> Important: the experiment below should be treated as a simulation. In practice, the network must  predict either $\\epsilon$ or $x_0$ or $\\tilde{\\mu}_\\theta$. Here, the value of $epsilon$ is simply subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_step(epsilon, x_t, t_step, return_noise=False):\n",
    "    \"\"\"\n",
    "    [EN] Performs a single step in the reverse diffusion process\n",
    "         Going from t to t-1 by predicting and removing noise\n",
    "    \n",
    "    [CN] æ‰§è¡Œåå‘æ‰©æ•£è¿‡ç¨‹ä¸­çš„å•ä¸ªæ­¥éª¤\n",
    "         é€šè¿‡é¢„æµ‹å’Œç§»é™¤å™ªå£°ä»tåˆ°t-1\n",
    "    \"\"\"\n",
    "    \n",
    "    # [CN] åŸºäºepsilonä¼°è®¡x_0\n",
    "    x_0_pred=(x_t-(1-alphas_cumprod[t_step]).sqrt()*epsilon)/(alphas_cumprod_sqrt[t_step])\n",
    "    if t_step==0:\n",
    "        # [CN] å¦‚æœæ˜¯æœ€åä¸€æ­¥(t=0)ï¼Œç›´æ¥è¿”å›é¢„æµ‹çš„x_0\n",
    "        sample=x_0_pred\n",
    "        noise=torch.zeros_like(x_0_pred)\n",
    "    else:\n",
    "        # [CN] ä¼°è®¡å‡å€¼ï¼šä½¿ç”¨é¢„æµ‹çš„x_0å’Œå½“å‰x_tçš„çº¿æ€§ç»„åˆ\n",
    "        mean_pred=x_0_pred*(alphas_cumprod_sqrt[t_step-1]*betas[t_step])/(1-alphas_cumprod[t_step]) + x_t*(alphas_sqrt[t_step]*(1-alphas_cumprod[t_step-1]))/(1-alphas_cumprod[t_step])\n",
    "\n",
    "        # [CN] è®¡ç®—æ–¹å·®ï¼šä½¿ç”¨betaçš„å¹³æ–¹æ ¹\n",
    "        beta_pred=betas[t_step].sqrt() if t_step != 0 else 0\n",
    "\n",
    "        # [CN] ä»é¢„æµ‹åˆ†å¸ƒä¸­é‡‡æ ·\n",
    "        sample=mean_pred+beta_pred*torch.randn_like(x_t)\n",
    "        # [CN] è¿™ä¸ªå™ªå£°ä»…ç”¨äºæ¨¡æ‹Ÿç›®çš„ï¼ˆå› ä¸ºåœ¨å®é™…æƒ…å†µä¸‹x_0_predæ˜¯æœªçŸ¥çš„ï¼‰\n",
    "        noise=(sample-x_0_pred*alphas_cumprod_sqrt[t_step-1])/(1-alphas_cumprod[t_step-1]).sqrt()\n",
    "    \n",
    "    if return_noise:\n",
    "        return sample, noise\n",
    "    else:\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t,noise=forward_jump(1000-1,img_,return_noise=True)\n",
    "\n",
    "state_imgs=[x_t.numpy()]\n",
    "for t_step in reversed(range(1000)):\n",
    "    x_t,noise=reverse_step(noise,x_t,t_step,return_noise=True)\n",
    "    \n",
    "    if t_step % 200 == 0:\n",
    "        state_imgs.append(x_t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26eb9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for idx,state_img in enumerate(state_imgs):\n",
    "    plt.subplot(1,len(state_imgs),idx+1)\n",
    "    show(state_img.clip(-1,1))\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d9302",
   "metadata": {},
   "source": [
    "## Packaging into Components ç»„ä»¶å°è£…\n",
    "\n",
    "[English]\n",
    "The processes investigated above are neatly packaged into modular components for easier management of the diffusion framework.\n",
    "\n",
    "First, the forward process component `GaussianForwardProcess` encapsulates the functions of $q(x_t|x_0)$ and $q(x_t|x_{t-1})$.\n",
    "\n",
    "Below, we can see how different schedules of the variance parameter $\\beta$ affect how the noise level changes throughout the progression.\n",
    "\n",
    "[ä¸­æ–‡]\n",
    "ä¸Šé¢ç ”ç©¶çš„è¿‡ç¨‹è¢«æ•´é½åœ°æ‰“åŒ…æˆæ¨¡å—åŒ–ç»„ä»¶ï¼Œä»¥ä¾¿æ›´å®¹æ˜“åœ°ç®¡ç†æ‰©æ•£æ¡†æ¶ã€‚\n",
    "\n",
    "é¦–å…ˆï¼Œå‰å‘è¿‡ç¨‹ç»„ä»¶ `GaussianForwardProcess` å°è£…äº† $q(x_t|x_0)$ å’Œ $q(x_t|x_{t-1})$ çš„åŠŸèƒ½ã€‚\n",
    "\n",
    "åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ–¹å·®å‚æ•° $\\beta$ çš„ä¸åŒè°ƒåº¦æ–¹å¼å¦‚ä½•å½±å“å™ªå£°æ°´å¹³åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­çš„å˜åŒ–ã€‚\n",
    "\n",
    "[è°ƒåº¦è¯´æ˜]\n",
    "æˆ‘ä»¬å°†å±•ç¤ºå››ç§ä¸åŒçš„å™ªå£°è°ƒåº¦æ–¹æ¡ˆï¼š\n",
    "1. linearï¼ˆçº¿æ€§ï¼‰ï¼šå™ªå£°çº¿æ€§å¢åŠ \n",
    "2. quadraticï¼ˆäºŒæ¬¡ï¼‰ï¼šå™ªå£°æŒ‰äºŒæ¬¡å‡½æ•°å¢åŠ \n",
    "3. sigmoidï¼ˆSå‹ï¼‰ï¼šå™ªå£°æŒ‰Så½¢æ›²çº¿å¢åŠ \n",
    "4. cosineï¼ˆä½™å¼¦ï¼‰ï¼šå™ªå£°æŒ‰ä½™å¼¦å‡½æ•°è°ƒæ•´\n",
    "\n",
    "æ¯ç§è°ƒåº¦æ–¹æ¡ˆéƒ½ä¼šæ˜¾ç¤ºï¼š\n",
    "- å·¦ä¾§ï¼š$\\beta_t$ éšæ—¶é—´çš„å˜åŒ–æ›²çº¿\n",
    "- å³ä¾§ï¼š5ä¸ªæ—¶é—´æ­¥çš„å›¾åƒæ ·æœ¬ï¼Œå±•ç¤ºå™ªå£°çš„é€æ­¥æ·»åŠ è¿‡ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "\n",
    "D=128\n",
    "make_white=False\n",
    "save=False\n",
    "line_color='black' #'#9EFFB9'\n",
    "test_img=img[256-D:256+D,512-D:512+D,:]\n",
    "\n",
    "for schedule in ['linear','quadratic','sigmoid','cosine']:\n",
    "    fw=GaussianForwardProcess(1000,\n",
    "                              schedule)\n",
    "\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.subplot(1,6,1)    \n",
    "    plt.plot(fw.betas,color=line_color)\n",
    "    plt.title(schedule,color=line_color)\n",
    "    plt.xlabel(r'step $t$',color=line_color)\n",
    "    plt.ylabel(r'$\\beta_t$',color=line_color)\n",
    "    \n",
    "    if make_white:\n",
    "        plt.xticks(color='white')\n",
    "        plt.gca().tick_params(axis='x', colors='white')\n",
    "        plt.gca().tick_params(axis='y', colors='white')\n",
    "        plt.gca().spines['top'].set_color('white')\n",
    "        plt.gca().spines['right'].set_color('white')\n",
    "        plt.gca().spines['left'].set_color('white')\n",
    "        plt.gca().spines['bottom'].set_color('white')\n",
    "    for step in range(5):\n",
    "        plt.subplot(1,6,step+2)\n",
    "        plt.imshow(fw(test_img.permute(2,0,1).unsqueeze(0),torch.tensor(step*200))[0].permute(1,2,0))\n",
    "        plt.axis('off')        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    if save:\n",
    "        plt.savefig('{}.png'.format(schedule),\n",
    "                    dpi=200,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.0,\n",
    "                    transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489a8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
